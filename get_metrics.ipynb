{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import pickle\n",
    "from metrics import *\n",
    "import re\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "CATEGORIES_YAML = load_config(\"/hai/scratch/zwefers/seq2loc/metadata/level_classes.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"/hai/scratch/zwefers/seq2loc/metadata/hou_testset.csv\")\n",
    "\n",
    "\n",
    "implicitly_multi = [\n",
    "    \"actin-filaments\",\n",
    "    \"intermediate-filaments\",\n",
    "    \"centrosome\",\n",
    "    \"microtubules\",\n",
    "    \"endosomes\",\n",
    "    \"lysosomes\",\n",
    "    \"peroxisomes\"\n",
    "    \"lipid-droplets\"\n",
    "]\n",
    "pattern = \"|\".join(map(re.escape, implicitly_multi))\n",
    "\n",
    "single_testset = testset[~testset.level3.str.contains(\";\")]\n",
    "single_testset.loc[single_testset.level2.str.contains(\";\"), \"level2\"] = pd.NA\n",
    "single_testset.loc[\n",
    "    (single_testset.level1.str.contains(\";\")) &\n",
    "    ~((single_testset.level1.str.contains(pattern, na=False)) & (single_testset['level1'].str.count(\";\") == 1)), \n",
    "    \"level1\"] = pd.NA\n",
    "\n",
    "multi_testset = testset[~testset.uniprot_id.isin(single_testset.uniprot_id)]\n",
    "multi_testset.loc[~multi_testset.level2.str.contains(\";\"), \"level2\"] = pd.NA\n",
    "multi_testset.loc[~multi_testset.level1.str.contains(\";\"), \"level1\"] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE=True\n",
    "MULTI=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SINGLE:\n",
    "    tag = \"_single\"\n",
    "elif MULTI:\n",
    "    tag = \"_multi\"\n",
    "else:\n",
    "    tag = \"\"\n",
    "\n",
    "\n",
    "trainset = pd.read_csv(\"/hai/scratch/zwefers/seq2loc/metadata/hpa_uniprot_combined_trainset.csv\")\n",
    "outdir = \"outputs/seq2locbench/\"\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "for model in [\"prott5\", \"esm1\"]:\n",
    "    val_avg_df = []\n",
    "    test_metrics_avg_df = []\n",
    "    for level in [1,2,3]:\n",
    "        val_perclass_df = []\n",
    "        test_targets_all = []\n",
    "        test_probs_all = []\n",
    "        test_preds_all = []\n",
    "\n",
    "        for fold in range(5):\n",
    "            val_path = f\"{outdir}/{model}/{fold}_1Layer_combined_level{level}_testout.pkl\"\n",
    "            val_df = pd.read_pickle(val_path)\n",
    "            val_df = val_df.merge(trainset, \n",
    "                                left_on=\"ACC\", \n",
    "                                right_on=\"uniprot_id\", \n",
    "                                how=\"inner\")\n",
    "            val_probs = np.stack(val_df.preds.to_numpy())\n",
    "            val_targets = []\n",
    "            for locs in val_df[f\"level{level}\"].str.split(\";\").to_list():\n",
    "                val_targets.append([1 if loc in locs else 0 \n",
    "                                    for loc in CATEGORIES_YAML[f\"level{level}\"]])\n",
    "            val_targets = np.array(val_targets)\n",
    "\n",
    "            thresholds = [get_best_threshold_mcc(val_targets[:, i], val_probs[:, i]) \n",
    "                        for i in range(val_targets.shape[1])]\n",
    "            thresholds = np.array(thresholds)\n",
    "            #TODO: save thresholds\n",
    "\n",
    "            _, val_metrics_perclass, val_metrics_avg = all_metrics(val_targets, \n",
    "                                                                val_probs, \n",
    "                                                                thresholds=thresholds)\n",
    "            val_metrics_perclass[\"label\"] = CATEGORIES_YAML[f\"level{level}\"]\n",
    "            val_metrics_perclass[\"fold\"] = fold\n",
    "            val_metrics_avg[\"level\"] = level\n",
    "            val_metrics_avg[\"fold\"] = fold\n",
    "            val_perclass_df.append(val_metrics_perclass)\n",
    "            val_avg_df.append(val_metrics_avg)\n",
    "\n",
    "            test_path = f\"{outdir}/{model}/{fold}_1Layer_combined_level{level}_hou_testout.pkl\"\n",
    "            test_df = pd.read_pickle(test_path)\n",
    "            test_df = test_df.merge(testset, \n",
    "                                    left_on=\"ACC\", \n",
    "                                    right_on=\"uniprot_id\",\n",
    "                                    how=\"inner\")\n",
    "            if SINGLE:\n",
    "                test_df = test_df[test_df.uniprot_id.isin(single_testset[single_testset[f\"level{level}\"].notna()].uniprot_id)]\n",
    "            elif MULTI:\n",
    "                test_df = test_df[test_df.uniprot_id.isin(multi_testset[multi_testset[f\"level{level}\"].notna()].uniprot_id)]\n",
    "\n",
    "            \n",
    "            test_probs = np.stack(test_df.preds.to_numpy())\n",
    "            test_targets = []\n",
    "            for locs in test_df[f\"level{level}\"].str.split(\";\").to_list():\n",
    "                test_targets.append([1 if loc in locs else 0 \n",
    "                                    for loc in CATEGORIES_YAML[f\"level{level}\"]])\n",
    "            test_targets = np.array(test_targets)\n",
    "\n",
    "\n",
    "            test_preds = test_probs > thresholds[np.newaxis, :]\n",
    "\n",
    "            test_targets_all.append(test_targets)\n",
    "            test_probs_all.append(test_probs)   \n",
    "            test_preds_all.append(test_preds)\n",
    "\n",
    "        val_perclass_df = pd.concat(val_perclass_df)\n",
    "        val_perclass_df.to_csv(f\"{outdir}/{model}/val_metrics_perclass_level{level}{tag}.csv\", index=False)\n",
    "\n",
    "        test_targets_all = np.array(test_targets_all)\n",
    "        assert np.all(test_targets_all[0, :, :] == test_targets_all)\n",
    "        test_targets = test_targets_all[0, :, :]\n",
    "        test_probs = np.array(test_probs_all).mean(axis=0)\n",
    "        test_preds = (np.array(test_preds_all).mean(axis=0) > 0.5).astype(np.int32)\n",
    "\n",
    "\n",
    "        labels = np.array(CATEGORIES_YAML[f\"level{level}\"])\n",
    "        predicted_labels = [set(labels[np.where(pred==1)[0]]) for pred in test_preds]\n",
    "\n",
    "        #Cut out empty categories in testset like plastid\n",
    "        idxs = np.where(test_targets.sum(axis=0) != 0)[0]\n",
    "        test_targets = test_targets[:, idxs]\n",
    "        test_probs = test_probs[:, idxs]\n",
    "        test_preds = test_preds[:, idxs]\n",
    "        thresholds = thresholds[idxs]\n",
    "\n",
    "        _, test_metrics_perclass, test_metrics_avg = all_metrics(\n",
    "                                                                test_targets, \n",
    "                                                                test_probs, \n",
    "                                                                y_pred_bin = test_preds,\n",
    "                                                                thresholds=thresholds\n",
    "                                                                )\n",
    "        test_metrics_perclass[\"label\"] = np.array(CATEGORIES_YAML[f\"level{level}\"])[idxs]\n",
    "        test_metrics_perclass.to_csv(\n",
    "            f\"{outdir}/{model}/test_metrics_perclass_level{level}{tag}.csv\", index=False)\n",
    "        \n",
    "        test_metrics_avg[\"level\"] = level\n",
    "        test_metrics_avg_df.append(test_metrics_avg)\n",
    "\n",
    "    val_avg_df = pd.concat(val_avg_df)\n",
    "    val_avg_df.to_csv(f\"{outdir}/{model}/val_metrics_avg{tag}.csv\", index=False)\n",
    "    test_metrics_avg_df = pd.concat(test_metrics_avg_df)\n",
    "    test_metrics_avg_df.to_csv(f\"{outdir}/{model}/test_metrics_avg{tag}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
